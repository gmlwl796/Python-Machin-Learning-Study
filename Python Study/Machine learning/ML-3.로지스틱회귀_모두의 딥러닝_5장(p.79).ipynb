{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color = 'color'>모두의 딥러닝: 5장(p.79)</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color = blue>로지스틱 회귀분석에 대한 이해</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 선형회귀(linear)와 로지스틱회귀(logistic) 간의 공통점\n",
    "* 피처(입력/예측/독립)변수의 변화에 따라 타깃(출력/반응/종속)변수가 어떻게 변하는지를 설명하는 <br>관계식을 찾는 다는 점에서 회귀분석과 동일한 목표를 가짐\n",
    "* 또한 피처변수들의 회귀계수(coefficient)들을 선형적으로 결합(단순한 더하기로 연결)해 <br>타깃변수 예측이 가능한 분석이므로 선형회귀(linear regression)로 볼 수 있음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 선형회귀(linear)와 로지스틱회귀(logistic) 간의 차이점\n",
    "* 타깃변수의 척도에 따라 궁극적인 예측의 목적이 달라진다는 점에서 차이가 남\n",
    "* __선형회귀분석__: 타깃변수는 연속척도를 기준으로 하므로 <font color = 'red'>수치예측(regression)</font> 분석임\n",
    "* __로지스틱 회귀분석__: 타깃변수는 범주척도를 대상으로 하므로 <font color = 'red'>분류예측(classification)</font> 분석임\n",
    "* 이항형인 데이터에 적용하였을 때 종속 변수 y의 결과가 범위[0,1]로 제한됨\n",
    "* 종속 변수가 이진적이기 때문에 조건부 확률(P(y│x))의 분포가 정규분포 대신 이항 분포를 따름\n",
    "* 종속변수가 범주형이라 정규분포가 아니므로 연속선상의 수치예측이 아닌 범주 중의 하나일 확률을 예측하게 됨"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 로지스틱회귀 유형\n",
    "* 종속변수가 두 개의 범주를 가지는 문제: <font color = 'blue'>이항(binomial) 또는 이진(binary)</font> 로지스틱 회귀(logistic regression) \n",
    "* 종속변수가 두 개 이상의 범주를 가지는 문제: <font color = 'blue'>다항(multinomial, multiclass)</font> 또는 <font color = 'blue'>분화(polytomous)</font> 로지스틱 회귀(logistic regression) \n",
    "* 종속변수가 복수범주이며, 순서가 존재하는 문제: <font color = 'blue'>서수(ordinal)</font> 로지스틱 회귀(logistic regression)\n",
    "* (참고) <font color = 'green'>단순(simple)</font> 로지스틱: 피처가 1개인 모형, <font color = 'green'>다중(multiple)</font> 로지스틱: 피처가 2개 이상인 모형\n",
    "\n",
    "\n",
    "\n",
    "- 단일은 feature(독립변수)가 1개\n",
    "- 다중은 feature(독립변수)가 여러개\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color = blue>분류예측선 도출을 위한 로지스틱 함수 이해</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 분류문제에  선형회귀모델 대신 시그모이드 함수가 필요한 이유\n",
    "* 선형회귀에서는 최소자승법으로 실제 y값과 예측y값 간의 오차가 최소가 되도록 하는 최소자승법을 통해 연속선 상의 y값을 예측\n",
    "* 분류문제에서는 피처들이 입력되었을 때 타겟변수의 예측값으로 연속선상의 숫자가 아닌 0과 1과 같은 범주를 예측해야하므로 \n",
    "<br>선형회귀모델의 최소자승법을 그대로 사용할 수 없어 다른 활성화함수가 필요함\n",
    "<img src = './../../images/reg_sigmoid.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 로지스틱 함수\n",
    "* <font color = 'red'>로짓(logit)</font>의 의미: 어떤 일이 일어날 <font color = 'blue'>가능성(오즈; odds)</font>에 <font color = 'blue'>로그(log)</font>를 씌워 원하는 목표값을 만들어 내는 개념임 \n",
    "\n",
    "* 즉, 로지스틱 함수는 피처 x에 어떤 값이든(-∞ ~ +∞) 입력이 되었을 때, 출력 결과 y는 항상 0에서 1사이로 나타나도록 하는 함수를 의미함 \n",
    "* 일종의 확률밀도함수(probability density function)로 중심축 (x = 0)을 중심으로 좌측은 0으로 수렴하고 우측은 1로 수렴함\n",
    "* 또한 cutoff vlaue=0.5를 기준으로 추정된 y값이 낮으면 0으로, 높으면 1로 판단함 \n",
    "\n",
    "* 실제 많은 자연/사회현상에서는 특정 변수에 대한 확률값이 선형이 아닌 S-커브 형태를 따르는 경우가 많은데,<br> 이를 함수형태로 표현한 것이 로지스틱 함수이며, S자모양이란 뜻을 가진 단어인 <font color = 'blue'>시그모이드(sigmoid) 함수</font>로도 부름"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 일반회귀식(y = ax + b 또는 y = wx +b)으로 0 또는 1이라는 예측값을 바로 만들어 낼 수 없으므로 \n",
    "<br>y값이 0 또는 1이 나올 확률공식을 이용해 오즈비로 변환하여 로그를 취하면,\n",
    "<br> 피처변수 x의 입력값에 상관없이 추정되는 y값으로 0과 1에 가까운 확률로 만들어 낼 수 있음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = './../../images/logistic_function.png'>\n",
    "\n",
    "로짓변환을 하면 전형적인 y = ax + b의 선형식으로 만들 수 있음 <br>\n",
    "가파르게 꼬불꼬불하게 나올 수록 좋은 모양 -> 예측이 더 편리함"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 로지스틱(시그모이드) 함수의 특성\n",
    "* 0과 1로 나누어진 이진분류 결과를 예측하기 위해서 최소자승회귀법에 의한 일반직선이 아닌 S자 형태의 선을 그어주는 함수가 필요함 \n",
    "* 이러한 S자 형태의 선을 만들어 주는 함수가 시그모이드함수로 기울기 a와 절편 b에 따라 함수의 모양에 변화가 나타나게 됨\n",
    "<img src = './../../images/sigmoid_ab.png'>\n",
    "\n",
    "가급적이면 0과 1(위아래쪽)에 가까울수록 예측 가능. 그 사이에 들어있으면 예측하기 어려움"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 시그모이드함수의 기울기 a와 절편 b에 따라 발생하는 오차의 크기는 달라짐\n",
    "<img src = './../../images/sigmoid_ab_error.png'>\n",
    "\n",
    "- 제일 왼쪽그림에서 a가 작을 때 그래프보면 선이 0도 아니고 1도 아니라서 분류하기 어렵다. <br>\n",
    "- 오른쪽 그림을 보면, 절편에 따라서 좌/우로 움직임. 기울기를 빨간선이 나오는 것으로 세팅을 해야 그림이 나오는건데, 절편의 값을 작거나 크게 세팅을 하면 기울기는 같으나 정확한 예측이 안되고 방향도 반대가 될 수 있을 가능성이 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 로지스틱회귀 분류예측의 비용함수(Cost Function)\n",
    "* 로지스틱회귀 이용 분류예측식의 예측오차를 줄이기 위한 방법을 정의한 함수로 비용(cost)/손실(loss)/목적(objective)/오차(error) 함수라고 함\n",
    "* 손실함수값을 최소화하기위해 분류예측 시그모이드함수 파라미터인 기울기(a)/가중치(weight)와 절편(b)/편차(bias)를 미분을 통해 조정하는 것임\n",
    "* 분류예측(classification)에서 가장 대표적인 비용함수는 \n",
    "<br>실제/예측 y값이 0과 1일 때의 로그함수 2개를 결합해서 사용하는 분류오차(classification error)임\n",
    "<img src = './../../images/logistic_costfunction.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color = blue>로지스틱 회귀분석에 대한 경사하강법</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터 준비: 피처 x변수와 타깃 y변수\n",
    "* 공부시간(x: 피처/입력/예측/독립변수)에 따른 합격여부(y: 타깃/출력/반응/종속변수)간 관계\n",
    "<img src = './../../images/logistic_study_test.png' align = 'left'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(2, 0), (4, 0), (6, 0), (8, 1), (10, 1), (12, 1), (14, 1)]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 직접 피처(x)와 타깃(y) 변수값 할당하는 경우\n",
    "x = [2, 4, 6, 8, 10, 12, 14] # 공부시간\n",
    "y = [0, 0, 0, 1, 1, 1, 1] # 합격여부\n",
    "data = list(zip(x, y))\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "공부시간(x): [2, 4, 6, 8, 10, 12, 14]\n",
      "합격여부(y): [0, 0, 0, 1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "# data 객체에 들어 있던 (피처, 타깃) 데이터조합에서 피처와 타깃 데이터를 별도로 분리해내는 경우\n",
    "x_data = [i[0] for i in data]\n",
    "print('공부시간(x):', x_data)\n",
    "\n",
    "y_data = [j[1] for j in data]\n",
    "print('합격여부(y):', y_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 분류예측식 준비: 임의의 기울기 a와 절편 b값 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 텐서플로 라이브러리 로딩\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tensorflow.python.ops.variables.RefVariable'>\n",
      "<tf.Variable 'Variable:0' shape=(1,) dtype=float64_ref>\n",
      "<class 'tensorflow.python.ops.variables.RefVariable'>\n",
      "<tf.Variable 'Variable_1:0' shape=(1,) dtype=float64_ref>\n"
     ]
    }
   ],
   "source": [
    "# 기울기 a: 임의구간에서 텐서플로가 무작위 추출\n",
    "a = tf.Variable(tf.random_uniform([1], dtype = tf.float64, seed = 0))\n",
    "print(type(a))\n",
    "print(a)\n",
    "\n",
    "# 절편 b: 임의구간에서 텐서플로가 무작위 추출\n",
    "b = tf.Variable(tf.random_uniform([1], dtype = tf.float64, seed = 0))\n",
    "print(type(b))\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 분류예측식 설정\n",
    "<img src = './../../images/logistic_formula.png' align = 'left'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 시그모이드 함수를 설정함\n",
    "import numpy as np\n",
    "y_pred = 1 / (1 + np.e**(-a * x_data + b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 손실함수 설정\n",
    "<img src = './../../images/logistic_loss_function.png'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 로그함수를 이용한 오차계산\n",
    "loss = tf.reduce_mean(-np.array(y_data) * tf.log(y_pred) - (1 - np.array(y_data)) * tf.log(1 - y_pred))\n",
    "# loss = -tf.reduce_mean(np.array(y_data) * tf.log(y_pred) + (1 - np.array(y_data)) * tf.log(1 - y_pred))\n",
    "# - 실제 y값(y_data)와 예측 y값(y_pred)간 오차를 구하고 그 평균값을 loss에 저장함"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 학습률과 최적함수 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전체 데이터셋 중에서 어느정도 비율로 부분샘플을 입력해 파라미터를 구할 것인지 설정\n",
    "learning_rate = 0.5\n",
    "\n",
    "# 파라미터(가중치와 편향)를 조율해 가면서 실제 y값과의 오차를 어떻게 줄여 나갈지 설정\n",
    "gradient_descent = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 텐서플로 라이브러리를 이용한 경사하강법 실시"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:    0 ==> 기울기 a = 0.0273, y절편 b =  0.9918 ==> loss =  0.7760\n",
      "Epoch:  100 ==> 기울기 a = 1.0283, y절편 b =  5.1931 ==> loss =  0.2407\n",
      "Epoch:  200 ==> 기울기 a = 0.9658, y절편 b =  6.4925 ==> loss =  0.1125\n",
      "Epoch:  300 ==> 기울기 a = 1.0864, y절편 b =  7.3633 ==> loss =  0.0970\n",
      "Epoch:  400 ==> 기울기 a = 1.1876, y절편 b =  8.0879 ==> loss =  0.0863\n",
      "Epoch:  500 ==> 기울기 a = 1.2757, y절편 b =  8.7162 ==> loss =  0.0783\n",
      "Epoch:  600 ==> 기울기 a = 1.3543, y절편 b =  9.2751 ==> loss =  0.0719\n",
      "Epoch:  700 ==> 기울기 a = 1.4257, y절편 b =  9.7813 ==> loss =  0.0667\n",
      "Epoch:  800 ==> 기울기 a = 1.4912, y절편 b = 10.2456 ==> loss =  0.0623\n",
      "Epoch:  900 ==> 기울기 a = 1.5520, y절편 b = 10.6758 ==> loss =  0.0585\n",
      "Epoch: 1000 ==> 기울기 a = 1.6089, y절편 b = 11.0773 ==> loss =  0.0552\n",
      "Epoch: 1100 ==> 기울기 a = 1.6623, y절편 b = 11.4544 ==> loss =  0.0523\n",
      "Epoch: 1200 ==> 기울기 a = 1.7127, y절편 b = 11.8102 ==> loss =  0.0497\n",
      "Epoch: 1300 ==> 기울기 a = 1.7605, y절편 b = 12.1475 ==> loss =  0.0474\n",
      "Epoch: 1400 ==> 기울기 a = 1.8060, y절편 b = 12.4682 ==> loss =  0.0453\n",
      "Epoch: 1500 ==> 기울기 a = 1.8495, y절편 b = 12.7742 ==> loss =  0.0434\n",
      "Epoch: 1600 ==> 기울기 a = 1.8910, y절편 b = 13.0669 ==> loss =  0.0416\n",
      "Epoch: 1700 ==> 기울기 a = 1.9309, y절편 b = 13.3475 ==> loss =  0.0400\n",
      "Epoch: 1800 ==> 기울기 a = 1.9692, y절편 b = 13.6170 ==> loss =  0.0386\n",
      "Epoch: 1900 ==> 기울기 a = 2.0061, y절편 b = 13.8764 ==> loss =  0.0372\n",
      "Epoch: 2000 ==> 기울기 a = 2.0417, y절편 b = 14.1265 ==> loss =  0.0359\n",
      "Epoch: 2100 ==> 기울기 a = 2.0760, y절편 b = 14.3679 ==> loss =  0.0347\n",
      "Epoch: 2200 ==> 기울기 a = 2.1092, y절편 b = 14.6013 ==> loss =  0.0336\n",
      "Epoch: 2300 ==> 기울기 a = 2.1414, y절편 b = 14.8273 ==> loss =  0.0326\n",
      "Epoch: 2400 ==> 기울기 a = 2.1725, y절편 b = 15.0462 ==> loss =  0.0316\n",
      "Epoch: 2500 ==> 기울기 a = 2.2028, y절편 b = 15.2586 ==> loss =  0.0307\n",
      "Epoch: 2600 ==> 기울기 a = 2.2321, y절편 b = 15.4649 ==> loss =  0.0298\n",
      "Epoch: 2700 ==> 기울기 a = 2.2607, y절편 b = 15.6653 ==> loss =  0.0290\n",
      "Epoch: 2800 ==> 기울기 a = 2.2884, y절편 b = 15.8603 ==> loss =  0.0282\n",
      "Epoch: 2900 ==> 기울기 a = 2.3155, y절편 b = 16.0502 ==> loss =  0.0275\n",
      "Epoch: 3000 ==> 기울기 a = 2.3418, y절편 b = 16.2351 ==> loss =  0.0268\n",
      "Epoch: 3100 ==> 기울기 a = 2.3675, y절편 b = 16.4154 ==> loss =  0.0261\n",
      "Epoch: 3200 ==> 기울기 a = 2.3926, y절편 b = 16.5913 ==> loss =  0.0255\n",
      "Epoch: 3300 ==> 기울기 a = 2.4170, y절편 b = 16.7630 ==> loss =  0.0249\n",
      "Epoch: 3400 ==> 기울기 a = 2.4409, y절편 b = 16.9308 ==> loss =  0.0243\n",
      "Epoch: 3500 ==> 기울기 a = 2.4643, y절편 b = 17.0947 ==> loss =  0.0238\n",
      "Epoch: 3600 ==> 기울기 a = 2.4871, y절편 b = 17.2550 ==> loss =  0.0232\n",
      "Epoch: 3700 ==> 기울기 a = 2.5095, y절편 b = 17.4118 ==> loss =  0.0227\n",
      "Epoch: 3800 ==> 기울기 a = 2.5314, y절편 b = 17.5653 ==> loss =  0.0222\n",
      "Epoch: 3900 ==> 기울기 a = 2.5528, y절편 b = 17.7156 ==> loss =  0.0218\n",
      "Epoch: 4000 ==> 기울기 a = 2.5738, y절편 b = 17.8628 ==> loss =  0.0213\n",
      "Epoch: 4100 ==> 기울기 a = 2.5943, y절편 b = 18.0072 ==> loss =  0.0209\n",
      "Epoch: 4200 ==> 기울기 a = 2.6145, y절편 b = 18.1486 ==> loss =  0.0205\n",
      "Epoch: 4300 ==> 기울기 a = 2.6343, y절편 b = 18.2874 ==> loss =  0.0201\n",
      "Epoch: 4400 ==> 기울기 a = 2.6537, y절편 b = 18.4236 ==> loss =  0.0197\n",
      "Epoch: 4500 ==> 기울기 a = 2.6728, y절편 b = 18.5573 ==> loss =  0.0194\n",
      "Epoch: 4600 ==> 기울기 a = 2.6915, y절편 b = 18.6885 ==> loss =  0.0190\n",
      "Epoch: 4700 ==> 기울기 a = 2.7099, y절편 b = 18.8175 ==> loss =  0.0187\n",
      "Epoch: 4800 ==> 기울기 a = 2.7280, y절편 b = 18.9441 ==> loss =  0.0184\n",
      "Epoch: 4900 ==> 기울기 a = 2.7457, y절편 b = 19.0686 ==> loss =  0.0180\n",
      "Epoch: 5000 ==> 기울기 a = 2.7632, y절편 b = 19.1910 ==> loss =  0.0177\n"
     ]
    }
   ],
   "source": [
    "# 텐서플로 세션객체를 sess라는 별칭으로 실행\n",
    "with tf.Session() as sess:\n",
    "    \n",
    "    # 텐서플로 세션객체를 초기화\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    # 2000번의 경사하강법 실행반복\n",
    "    for i in range(5001):\n",
    "        \n",
    "        # rmse값이 촤소화되도록 경사하강법을 지속적으로 실시\n",
    "        sess.run(gradient_descent)\n",
    "\n",
    "        # 매 100번째 경사하강법 실행결과를 출력\n",
    "        if i % 100 == 0:\n",
    "            print(\"Epoch: %4.0f ==> 기울기 a = %6.4f, y절편 b = %7.4f ==> loss = %7.04f\" \n",
    "                  % (i, sess.run(a), sess.run(b), sess.run(loss)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color = blue>여러 피처값을 이용한 다중 로지스틱 회귀분석에 대한 경사하강법</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터 준비: 피처 x변수셋과 타깃 y변수\n",
    "* 공부시간(x1)과 과외횟수(x2): 피처/입력/예측/독립변수)에 따른 합격여부(y: 타깃/출력/반응/종속변수)간 관계\n",
    "<img src = './../../images/logistic_study_lesson_test.png' align = 'left'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 실행할 때마다 같은 결과를 출력하기 위한 seed 값 설정\n",
    "seed = 0\n",
    "np.random.seed(seed)\n",
    "tf.set_random_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2,  3],\n",
       "       [ 4,  3],\n",
       "       [ 6,  4],\n",
       "       [ 8,  6],\n",
       "       [10,  7],\n",
       "       [12,  8],\n",
       "       [14,  9]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 피처셋 x1(공부시간), x2(과외횟수)의 데이터 값\n",
    "x_data = np.array([[2, 3],[4, 3],[6, 4],[8, 6],[10, 7],[12, 8],[14, 9]])\n",
    "x_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 타겟변수 y(합격유무)의 데이터 값\n",
    "y_data = np.array([0, 0, 0, 1, 1, 1,1]).reshape(7, 1)\n",
    "# - .reshape()함수를 이용해서 배열객체의 저장구조를 피처셋x 구조와 동일하게 맞춤\n",
    "y_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 피처셋과 타겟변수 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 피처셋 x1과 x2, 타겟변수 y값을 저장해 놓을 객체준비\n",
    "\n",
    "X = tf.placeholder(tf.float64, shape=[None, 2])\n",
    "# - 피처셋 x1과 x2를 행은 상관없이 2열 구조로 저장준비\n",
    "\n",
    "Y = tf.placeholder(tf.float64, shape=[None, 1])\n",
    "# - 타겟변수 y를 행은 상관없이 1열 구조로 저장준비"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 임의의 가중치와 편향 값 설저"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 기울기 a와 bias b의 값을 임의로 정함.\n",
    "a = tf.Variable(tf.random_uniform([2, 1], dtype=tf.float64)) \n",
    "# - [2, 1] 의미: 들어오는 값은 2개, 나가는 값은 1개\n",
    "\n",
    "b = tf.Variable(tf.random_uniform([1], dtype=tf.float64))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 분류예측식 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y 시그모이드 함수의 방정식을 세움\n",
    "y = tf.sigmoid(tf.matmul(X, a) + b)\n",
    "# - a1x1 + a2x2 ==> 행렬곱을 이용해 [a1 a2] * [x1, x2] 형태로 투입연산"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 손실함수 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 오차를 구하는 함수\n",
    "loss = -tf.reduce_mean(Y * tf.log(y) + (1 - Y) * tf.log(1 - y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 학습률과 최적함수 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습률 값\n",
    "learning_rate = 0.1\n",
    "\n",
    "# 오차를 최소로 하는 값 찾기\n",
    "gradient_decent = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Cast:0' shape=(?, 1) dtype=float64>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# y값을 0과 1로 예측\n",
    "predicted = tf.cast(y > 0.5, dtype=tf.float64)\n",
    "predicted\n",
    "# - y > 0.5이면 True처리, 아니면 False처리\n",
    "# .cast()로 자료형을 변경해줌"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Mean_2:0' shape=() dtype=float64>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 정확도 계산\n",
    "accuracy = tf.reduce_mean(tf.cast(tf.equal(predicted, Y), dtype=tf.float64))\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 학습실시"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step=300, a1=0.8011, a2=-0.5327, b=-2.4374, loss=0.2664\n",
      "step=600, a1=0.8076, a2=-0.2704, b=-3.9058, loss=0.1909\n",
      "step=900, a1=0.7222, a2=0.0505, b=-4.9678, loss=0.1494\n",
      "step=1200, a1=0.6217, a2=0.3522, b=-5.8083, loss=0.1224\n",
      "step=1500, a1=0.5251, a2=0.6221, b=-6.5054, loss=0.1034\n",
      "step=1800, a1=0.4373, a2=0.8606, b=-7.1016, loss=0.0893\n",
      "step=2100, a1=0.3591, a2=1.0715, b=-7.6227, loss=0.0786\n",
      "step=2400, a1=0.2897, a2=1.2589, b=-8.0856, loss=0.0701\n",
      "step=2700, a1=0.2281, a2=1.4265, b=-8.5021, loss=0.0632\n",
      "step=3000, a1=0.1733, a2=1.5774, b=-8.8807, loss=0.0576\n",
      "\n",
      "공부 시간: 7, 개인 과외 수: 6\n",
      "합격 가능성:  85.78 %\n"
     ]
    }
   ],
   "source": [
    "# 학습실시\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    for i in range(3001):\n",
    "        a_, b_, loss_, _ = sess.run([a, b, loss, gradient_decent], feed_dict={X: x_data, Y: y_data})\n",
    "        if (i + 1) % 300 == 0:\n",
    "            print(\"step=%d, a1=%.4f, a2=%.4f, b=%.4f, loss=%.4f\" % (i + 1, a_[0], a_[1], b_, loss_))\n",
    "\n",
    "### 테스트용 피처값에 따른 y값 예측\n",
    "    new_x = np.array([7, 6.]).reshape(1, 2)  \n",
    "    # - [7, 6]은 각각 공부시간(x1)과 과외 수업수(x2)\n",
    "    # - 2개 피처이므로 1행에 2열 구조로 준비\n",
    "\n",
    "    new_y = sess.run(y, feed_dict = {X: new_x})\n",
    "\n",
    "    print(\"\\n공부 시간: %d, 개인 과외 수: %d\" % (new_x[:,0], new_x[:,1]))\n",
    "    print(\"합격 가능성: %6.2f %%\" % (new_y*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# End of Source"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
